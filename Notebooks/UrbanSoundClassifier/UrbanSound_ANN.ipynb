{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8debdf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fccfc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cfea585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metadata= pd.read_csv(r\"C:\\Users\\Rashiqua Munshi\\Downloads\\ProjectSchool\\UrbanSound8K.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a57224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>159.522205</td>\n",
       "      <td>163.522205</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>181.142431</td>\n",
       "      <td>183.284976</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>242.691902</td>\n",
       "      <td>246.197885</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>253.209850</td>\n",
       "      <td>255.741948</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>332.289233</td>\n",
       "      <td>334.821332</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      slice_file_name   fsID       start         end  salience  fold  classID   \n",
       "8727  99812-1-2-0.wav  99812  159.522205  163.522205         2     7        1  \\\n",
       "8728  99812-1-3-0.wav  99812  181.142431  183.284976         2     7        1   \n",
       "8729  99812-1-4-0.wav  99812  242.691902  246.197885         2     7        1   \n",
       "8730  99812-1-5-0.wav  99812  253.209850  255.741948         2     7        1   \n",
       "8731  99812-1-6-0.wav  99812  332.289233  334.821332         2     7        1   \n",
       "\n",
       "         class  \n",
       "8727  car_horn  \n",
       "8728  car_horn  \n",
       "8729  car_horn  \n",
       "8730  car_horn  \n",
       "8731  car_horn  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74391051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "dog_bark            1000\n",
       "children_playing    1000\n",
       "air_conditioner     1000\n",
       "street_music        1000\n",
       "engine_idling       1000\n",
       "jackhammer          1000\n",
       "drilling            1000\n",
       "siren                929\n",
       "car_horn             429\n",
       "gun_shot             374\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca55ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "audio_dataset_path=r\"C:\\Users\\Rashiqua Munshi\\Downloads\\ProjectSchool\\archive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ecfed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file) \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2703e790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3549it [00:48, 71.81it/s] C:\\Users\\Rashiqua Munshi\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "8315it [01:52, 86.63it/s] C:\\Users\\Rashiqua Munshi\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "8328it [01:52, 97.55it/s]C:\\Users\\Rashiqua Munshi\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\librosa\\core\\spectrum.py:256: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "8732it [01:58, 73.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "### Now we iterate through every audio file and extract features \n",
    "### using Mel-Frequency Cepstral Coefficients\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    final_class_labels=row[\"class\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e42e4dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-211.93698, 62.581203, -122.81315, -60.745293...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-417.0052, 99.336624, -42.995586, 51.073326, ...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-452.39316, 112.36253, -37.578068, 43.195866,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-406.47922, 91.1966, -25.043556, 42.78452, 11...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-439.63873, 103.86224, -42.658787, 50.690277,...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature             class\n",
       "0  [-211.93698, 62.581203, -122.81315, -60.745293...          dog_bark\n",
       "1  [-417.0052, 99.336624, -42.995586, 51.073326, ...  children_playing\n",
       "2  [-452.39316, 112.36253, -37.578068, 43.195866,...  children_playing\n",
       "3  [-406.47922, 91.1966, -25.043556, 42.78452, 11...  children_playing\n",
       "4  [-439.63873, 103.86224, -42.658787, 50.690277,...  children_playing"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20d7d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(extracted_features_df[\"feature\"].tolist())\n",
    "y=np.array(extracted_features_df[\"class\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "704077c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a99d352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0f950a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(pd.get_dummies(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fb683e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d830885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5937, 40)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e076d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Activation,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8856298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(200))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "          \n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b473471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4100      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20200     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 100)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 45,410\n",
      "Trainable params: 45,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1786182",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",metrics=[\"accuracy\"],optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e54dc6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "165/186 [=========================>....] - ETA: 0s - loss: 5.3979 - accuracy: 0.1583\n",
      "Epoch 1: val_loss improved from inf to 2.20187, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 1s 3ms/step - loss: 5.0442 - accuracy: 0.1615 - val_loss: 2.2019 - val_accuracy: 0.1469\n",
      "Epoch 2/100\n",
      "183/186 [============================>.] - ETA: 0s - loss: 2.1740 - accuracy: 0.2037\n",
      "Epoch 2: val_loss improved from 2.20187 to 2.04567, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 2.1741 - accuracy: 0.2043 - val_loss: 2.0457 - val_accuracy: 0.2844\n",
      "Epoch 3/100\n",
      "161/186 [========================>.....] - ETA: 0s - loss: 2.0215 - accuracy: 0.2962\n",
      "Epoch 3: val_loss improved from 2.04567 to 1.87725, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 2.0055 - accuracy: 0.2990 - val_loss: 1.8772 - val_accuracy: 0.3464\n",
      "Epoch 4/100\n",
      "174/186 [===========================>..] - ETA: 0s - loss: 1.8707 - accuracy: 0.3479\n",
      "Epoch 4: val_loss improved from 1.87725 to 1.67396, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 1.8626 - accuracy: 0.3482 - val_loss: 1.6740 - val_accuracy: 0.3855\n",
      "Epoch 5/100\n",
      "163/186 [=========================>....] - ETA: 0s - loss: 1.7114 - accuracy: 0.3852\n",
      "Epoch 5: val_loss improved from 1.67396 to 1.48671, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 1.7081 - accuracy: 0.3891 - val_loss: 1.4867 - val_accuracy: 0.4771\n",
      "Epoch 6/100\n",
      "172/186 [==========================>...] - ETA: 0s - loss: 1.5905 - accuracy: 0.4366\n",
      "Epoch 6: val_loss improved from 1.48671 to 1.36253, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 1.5896 - accuracy: 0.4374 - val_loss: 1.3625 - val_accuracy: 0.5239\n",
      "Epoch 7/100\n",
      "171/186 [==========================>...] - ETA: 0s - loss: 1.4791 - accuracy: 0.4799\n",
      "Epoch 7: val_loss improved from 1.36253 to 1.21255, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 1.4744 - accuracy: 0.4827 - val_loss: 1.2125 - val_accuracy: 0.6011\n",
      "Epoch 8/100\n",
      "176/186 [===========================>..] - ETA: 0s - loss: 1.3610 - accuracy: 0.5330\n",
      "Epoch 8: val_loss improved from 1.21255 to 1.15436, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 1.3603 - accuracy: 0.5324 - val_loss: 1.1544 - val_accuracy: 0.6288\n",
      "Epoch 9/100\n",
      "177/186 [===========================>..] - ETA: 0s - loss: 1.2737 - accuracy: 0.5613\n",
      "Epoch 9: val_loss improved from 1.15436 to 1.10539, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 1.2748 - accuracy: 0.5597 - val_loss: 1.1054 - val_accuracy: 0.6384\n",
      "Epoch 10/100\n",
      "168/186 [==========================>...] - ETA: 0s - loss: 1.2232 - accuracy: 0.5796\n",
      "Epoch 10: val_loss improved from 1.10539 to 1.02413, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 1.2130 - accuracy: 0.5835 - val_loss: 1.0241 - val_accuracy: 0.6775\n",
      "Epoch 11/100\n",
      "175/186 [===========================>..] - ETA: 0s - loss: 1.1125 - accuracy: 0.6168\n",
      "Epoch 11: val_loss improved from 1.02413 to 0.96993, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 1.1169 - accuracy: 0.6136 - val_loss: 0.9699 - val_accuracy: 0.6794\n",
      "Epoch 12/100\n",
      "182/186 [============================>.] - ETA: 0s - loss: 1.0763 - accuracy: 0.6269\n",
      "Epoch 12: val_loss improved from 0.96993 to 0.92202, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 1.0783 - accuracy: 0.6267 - val_loss: 0.9220 - val_accuracy: 0.6880\n",
      "Epoch 13/100\n",
      "177/186 [===========================>..] - ETA: 0s - loss: 1.0180 - accuracy: 0.6577\n",
      "Epoch 13: val_loss improved from 0.92202 to 0.86386, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 1.0249 - accuracy: 0.6554 - val_loss: 0.8639 - val_accuracy: 0.7281\n",
      "Epoch 14/100\n",
      "166/186 [=========================>....] - ETA: 0s - loss: 0.9577 - accuracy: 0.6739\n",
      "Epoch 14: val_loss improved from 0.86386 to 0.80915, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.9632 - accuracy: 0.6722 - val_loss: 0.8092 - val_accuracy: 0.7471\n",
      "Epoch 15/100\n",
      "177/186 [===========================>..] - ETA: 0s - loss: 0.9193 - accuracy: 0.6886\n",
      "Epoch 15: val_loss improved from 0.80915 to 0.76493, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.9159 - accuracy: 0.6879 - val_loss: 0.7649 - val_accuracy: 0.7615\n",
      "Epoch 16/100\n",
      "171/186 [==========================>...] - ETA: 0s - loss: 0.8717 - accuracy: 0.7008\n",
      "Epoch 16: val_loss improved from 0.76493 to 0.74981, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.8645 - accuracy: 0.7022 - val_loss: 0.7498 - val_accuracy: 0.7691\n",
      "Epoch 17/100\n",
      "176/186 [===========================>..] - ETA: 0s - loss: 0.8223 - accuracy: 0.7216\n",
      "Epoch 17: val_loss improved from 0.74981 to 0.72215, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.8279 - accuracy: 0.7191 - val_loss: 0.7221 - val_accuracy: 0.7681\n",
      "Epoch 18/100\n",
      "165/186 [=========================>....] - ETA: 0s - loss: 0.8068 - accuracy: 0.7312\n",
      "Epoch 18: val_loss improved from 0.72215 to 0.68361, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.8038 - accuracy: 0.7317 - val_loss: 0.6836 - val_accuracy: 0.7758\n",
      "Epoch 19/100\n",
      "168/186 [==========================>...] - ETA: 0s - loss: 0.7979 - accuracy: 0.7284\n",
      "Epoch 19: val_loss did not improve from 0.68361\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.7968 - accuracy: 0.7293 - val_loss: 0.6846 - val_accuracy: 0.7920\n",
      "Epoch 20/100\n",
      "177/186 [===========================>..] - ETA: 0s - loss: 0.7633 - accuracy: 0.7429\n",
      "Epoch 20: val_loss improved from 0.68361 to 0.64113, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.7647 - accuracy: 0.7431 - val_loss: 0.6411 - val_accuracy: 0.8025\n",
      "Epoch 21/100\n",
      "164/186 [=========================>....] - ETA: 0s - loss: 0.7200 - accuracy: 0.7622\n",
      "Epoch 21: val_loss improved from 0.64113 to 0.63149, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.7151 - accuracy: 0.7633 - val_loss: 0.6315 - val_accuracy: 0.7929\n",
      "Epoch 22/100\n",
      "175/186 [===========================>..] - ETA: 0s - loss: 0.7066 - accuracy: 0.7613\n",
      "Epoch 22: val_loss improved from 0.63149 to 0.59018, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.7058 - accuracy: 0.7598 - val_loss: 0.5902 - val_accuracy: 0.8006\n",
      "Epoch 23/100\n",
      "176/186 [===========================>..] - ETA: 0s - loss: 0.6677 - accuracy: 0.7690\n",
      "Epoch 23: val_loss improved from 0.59018 to 0.58137, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.6698 - accuracy: 0.7689 - val_loss: 0.5814 - val_accuracy: 0.8063\n",
      "Epoch 24/100\n",
      "173/186 [==========================>...] - ETA: 0s - loss: 0.6567 - accuracy: 0.7728\n",
      "Epoch 24: val_loss did not improve from 0.58137\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.7738 - val_loss: 0.5816 - val_accuracy: 0.8092\n",
      "Epoch 25/100\n",
      "176/186 [===========================>..] - ETA: 0s - loss: 0.6120 - accuracy: 0.7901\n",
      "Epoch 25: val_loss did not improve from 0.58137\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.7878 - val_loss: 0.5947 - val_accuracy: 0.8034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "177/186 [===========================>..] - ETA: 0s - loss: 0.6221 - accuracy: 0.7860\n",
      "Epoch 26: val_loss improved from 0.58137 to 0.54634, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.7829 - val_loss: 0.5463 - val_accuracy: 0.8187\n",
      "Epoch 27/100\n",
      "179/186 [===========================>..] - ETA: 0s - loss: 0.6015 - accuracy: 0.7947\n",
      "Epoch 27: val_loss improved from 0.54634 to 0.53755, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.7932 - val_loss: 0.5376 - val_accuracy: 0.8139\n",
      "Epoch 28/100\n",
      "181/186 [============================>.] - ETA: 0s - loss: 0.5768 - accuracy: 0.8090\n",
      "Epoch 28: val_loss improved from 0.53755 to 0.50349, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.8092 - val_loss: 0.5035 - val_accuracy: 0.8321\n",
      "Epoch 29/100\n",
      "181/186 [============================>.] - ETA: 0s - loss: 0.5550 - accuracy: 0.8109\n",
      "Epoch 29: val_loss improved from 0.50349 to 0.50098, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.8088 - val_loss: 0.5010 - val_accuracy: 0.8359\n",
      "Epoch 30/100\n",
      "179/186 [===========================>..] - ETA: 0s - loss: 0.5629 - accuracy: 0.8073\n",
      "Epoch 30: val_loss did not improve from 0.50098\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.8058 - val_loss: 0.5014 - val_accuracy: 0.8330\n",
      "Epoch 31/100\n",
      "178/186 [===========================>..] - ETA: 0s - loss: 0.5395 - accuracy: 0.8074\n",
      "Epoch 31: val_loss improved from 0.50098 to 0.49121, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.8073 - val_loss: 0.4912 - val_accuracy: 0.8473\n",
      "Epoch 32/100\n",
      "175/186 [===========================>..] - ETA: 0s - loss: 0.5409 - accuracy: 0.8112\n",
      "Epoch 32: val_loss improved from 0.49121 to 0.47778, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.8100 - val_loss: 0.4778 - val_accuracy: 0.8387\n",
      "Epoch 33/100\n",
      "181/186 [============================>.] - ETA: 0s - loss: 0.5365 - accuracy: 0.8172\n",
      "Epoch 33: val_loss improved from 0.47778 to 0.47610, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.8167 - val_loss: 0.4761 - val_accuracy: 0.8454\n",
      "Epoch 34/100\n",
      "181/186 [============================>.] - ETA: 0s - loss: 0.5249 - accuracy: 0.8172\n",
      "Epoch 34: val_loss improved from 0.47610 to 0.46717, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8179 - val_loss: 0.4672 - val_accuracy: 0.8445\n",
      "Epoch 35/100\n",
      "181/186 [============================>.] - ETA: 0s - loss: 0.4995 - accuracy: 0.8234\n",
      "Epoch 35: val_loss did not improve from 0.46717\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8245 - val_loss: 0.4844 - val_accuracy: 0.8349\n",
      "Epoch 36/100\n",
      "176/186 [===========================>..] - ETA: 0s - loss: 0.5127 - accuracy: 0.8308\n",
      "Epoch 36: val_loss did not improve from 0.46717\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8304 - val_loss: 0.4879 - val_accuracy: 0.8397\n",
      "Epoch 37/100\n",
      "171/186 [==========================>...] - ETA: 0s - loss: 0.4943 - accuracy: 0.8306\n",
      "Epoch 37: val_loss improved from 0.46717 to 0.45910, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8322 - val_loss: 0.4591 - val_accuracy: 0.8521\n",
      "Epoch 38/100\n",
      "172/186 [==========================>...] - ETA: 0s - loss: 0.4533 - accuracy: 0.8416\n",
      "Epoch 38: val_loss did not improve from 0.45910\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.8410 - val_loss: 0.4772 - val_accuracy: 0.8416\n",
      "Epoch 39/100\n",
      "157/186 [========================>.....] - ETA: 0s - loss: 0.4793 - accuracy: 0.8314\n",
      "Epoch 39: val_loss improved from 0.45910 to 0.44857, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8334 - val_loss: 0.4486 - val_accuracy: 0.8645\n",
      "Epoch 40/100\n",
      "176/186 [===========================>..] - ETA: 0s - loss: 0.4678 - accuracy: 0.8395\n",
      "Epoch 40: val_loss did not improve from 0.44857\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8385 - val_loss: 0.4657 - val_accuracy: 0.8454\n",
      "Epoch 41/100\n",
      "178/186 [===========================>..] - ETA: 0s - loss: 0.4631 - accuracy: 0.8404\n",
      "Epoch 41: val_loss improved from 0.44857 to 0.43874, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8423 - val_loss: 0.4387 - val_accuracy: 0.8531\n",
      "Epoch 42/100\n",
      "176/186 [===========================>..] - ETA: 0s - loss: 0.4427 - accuracy: 0.8443\n",
      "Epoch 42: val_loss improved from 0.43874 to 0.43158, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.8432 - val_loss: 0.4316 - val_accuracy: 0.8597\n",
      "Epoch 43/100\n",
      "176/186 [===========================>..] - ETA: 0s - loss: 0.4397 - accuracy: 0.8471\n",
      "Epoch 43: val_loss did not improve from 0.43158\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8454 - val_loss: 0.4529 - val_accuracy: 0.8588\n",
      "Epoch 44/100\n",
      "183/186 [============================>.] - ETA: 0s - loss: 0.4358 - accuracy: 0.8477\n",
      "Epoch 44: val_loss improved from 0.43158 to 0.40049, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8472 - val_loss: 0.4005 - val_accuracy: 0.8655\n",
      "Epoch 45/100\n",
      "177/186 [===========================>..] - ETA: 0s - loss: 0.4284 - accuracy: 0.8531\n",
      "Epoch 45: val_loss did not improve from 0.40049\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8523 - val_loss: 0.4298 - val_accuracy: 0.8550\n",
      "Epoch 46/100\n",
      "184/186 [============================>.] - ETA: 0s - loss: 0.4373 - accuracy: 0.8526\n",
      "Epoch 46: val_loss did not improve from 0.40049\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8528 - val_loss: 0.4228 - val_accuracy: 0.8635\n",
      "Epoch 47/100\n",
      "185/186 [============================>.] - ETA: 0s - loss: 0.4123 - accuracy: 0.8574\n",
      "Epoch 47: val_loss did not improve from 0.40049\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8572 - val_loss: 0.4389 - val_accuracy: 0.8607\n",
      "Epoch 48/100\n",
      "182/186 [============================>.] - ETA: 0s - loss: 0.4094 - accuracy: 0.8601\n",
      "Epoch 48: val_loss did not improve from 0.40049\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8595 - val_loss: 0.4296 - val_accuracy: 0.8607\n",
      "Epoch 49/100\n",
      "175/186 [===========================>..] - ETA: 0s - loss: 0.4139 - accuracy: 0.8591\n",
      "Epoch 49: val_loss did not improve from 0.40049\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8599 - val_loss: 0.4234 - val_accuracy: 0.8693\n",
      "Epoch 50/100\n",
      "182/186 [============================>.] - ETA: 0s - loss: 0.4055 - accuracy: 0.8587\n",
      "Epoch 50: val_loss did not improve from 0.40049\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8580 - val_loss: 0.4060 - val_accuracy: 0.8683\n",
      "Epoch 51/100\n",
      "172/186 [==========================>...] - ETA: 0s - loss: 0.3716 - accuracy: 0.8721\n",
      "Epoch 51: val_loss improved from 0.40049 to 0.38663, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8723 - val_loss: 0.3866 - val_accuracy: 0.8740\n",
      "Epoch 52/100\n",
      "172/186 [==========================>...] - ETA: 0s - loss: 0.3969 - accuracy: 0.8603\n",
      "Epoch 52: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8609 - val_loss: 0.4249 - val_accuracy: 0.8740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "184/186 [============================>.] - ETA: 0s - loss: 0.3878 - accuracy: 0.8653\n",
      "Epoch 53: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8654 - val_loss: 0.4020 - val_accuracy: 0.8750\n",
      "Epoch 54/100\n",
      "173/186 [==========================>...] - ETA: 0s - loss: 0.3693 - accuracy: 0.8748\n",
      "Epoch 54: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3690 - accuracy: 0.8749 - val_loss: 0.3968 - val_accuracy: 0.8769\n",
      "Epoch 55/100\n",
      "157/186 [========================>.....] - ETA: 0s - loss: 0.3687 - accuracy: 0.8680\n",
      "Epoch 55: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8671 - val_loss: 0.4130 - val_accuracy: 0.8683\n",
      "Epoch 56/100\n",
      "176/186 [===========================>..] - ETA: 0s - loss: 0.3720 - accuracy: 0.8746\n",
      "Epoch 56: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8733 - val_loss: 0.4270 - val_accuracy: 0.8712\n",
      "Epoch 57/100\n",
      "173/186 [==========================>...] - ETA: 0s - loss: 0.3681 - accuracy: 0.8710\n",
      "Epoch 57: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8708 - val_loss: 0.3954 - val_accuracy: 0.8769\n",
      "Epoch 58/100\n",
      "157/186 [========================>.....] - ETA: 0s - loss: 0.3510 - accuracy: 0.8780\n",
      "Epoch 58: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8779 - val_loss: 0.4088 - val_accuracy: 0.8655\n",
      "Epoch 59/100\n",
      "185/186 [============================>.] - ETA: 0s - loss: 0.3768 - accuracy: 0.8684\n",
      "Epoch 59: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8685 - val_loss: 0.3995 - val_accuracy: 0.8826\n",
      "Epoch 60/100\n",
      "158/186 [========================>.....] - ETA: 0s - loss: 0.3559 - accuracy: 0.8752\n",
      "Epoch 60: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8740 - val_loss: 0.4178 - val_accuracy: 0.8798\n",
      "Epoch 61/100\n",
      "161/186 [========================>.....] - ETA: 0s - loss: 0.3610 - accuracy: 0.8729\n",
      "Epoch 61: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8757 - val_loss: 0.4151 - val_accuracy: 0.8721\n",
      "Epoch 62/100\n",
      "168/186 [==========================>...] - ETA: 0s - loss: 0.3621 - accuracy: 0.8793\n",
      "Epoch 62: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8787 - val_loss: 0.3931 - val_accuracy: 0.8769\n",
      "Epoch 63/100\n",
      "182/186 [============================>.] - ETA: 0s - loss: 0.3542 - accuracy: 0.8824\n",
      "Epoch 63: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8831 - val_loss: 0.3926 - val_accuracy: 0.8807\n",
      "Epoch 64/100\n",
      "181/186 [============================>.] - ETA: 0s - loss: 0.3475 - accuracy: 0.8843\n",
      "Epoch 64: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8841 - val_loss: 0.4210 - val_accuracy: 0.8788\n",
      "Epoch 65/100\n",
      "178/186 [===========================>..] - ETA: 0s - loss: 0.3524 - accuracy: 0.8785\n",
      "Epoch 65: val_loss did not improve from 0.38663\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8794 - val_loss: 0.4084 - val_accuracy: 0.8817\n",
      "Epoch 66/100\n",
      "186/186 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.8833\n",
      "Epoch 66: val_loss improved from 0.38663 to 0.38419, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8833 - val_loss: 0.3842 - val_accuracy: 0.8807\n",
      "Epoch 67/100\n",
      "182/186 [============================>.] - ETA: 0s - loss: 0.3738 - accuracy: 0.8736\n",
      "Epoch 67: val_loss did not improve from 0.38419\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8749 - val_loss: 0.3985 - val_accuracy: 0.8807\n",
      "Epoch 68/100\n",
      "155/186 [========================>.....] - ETA: 0s - loss: 0.3402 - accuracy: 0.8881\n",
      "Epoch 68: val_loss did not improve from 0.38419\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8882 - val_loss: 0.3931 - val_accuracy: 0.8845\n",
      "Epoch 69/100\n",
      "157/186 [========================>.....] - ETA: 0s - loss: 0.3416 - accuracy: 0.8879\n",
      "Epoch 69: val_loss improved from 0.38419 to 0.37939, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8897 - val_loss: 0.3794 - val_accuracy: 0.8836\n",
      "Epoch 70/100\n",
      "161/186 [========================>.....] - ETA: 0s - loss: 0.3212 - accuracy: 0.8940\n",
      "Epoch 70: val_loss did not improve from 0.37939\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8922 - val_loss: 0.3936 - val_accuracy: 0.8807\n",
      "Epoch 71/100\n",
      "158/186 [========================>.....] - ETA: 0s - loss: 0.3292 - accuracy: 0.8853\n",
      "Epoch 71: val_loss did not improve from 0.37939\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8866 - val_loss: 0.3871 - val_accuracy: 0.8769\n",
      "Epoch 72/100\n",
      "161/186 [========================>.....] - ETA: 0s - loss: 0.3070 - accuracy: 0.8901\n",
      "Epoch 72: val_loss did not improve from 0.37939\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8892 - val_loss: 0.3930 - val_accuracy: 0.8817\n",
      "Epoch 73/100\n",
      "158/186 [========================>.....] - ETA: 0s - loss: 0.3248 - accuracy: 0.8845\n",
      "Epoch 73: val_loss did not improve from 0.37939\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8845 - val_loss: 0.3874 - val_accuracy: 0.8817\n",
      "Epoch 74/100\n",
      "156/186 [========================>.....] - ETA: 0s - loss: 0.3024 - accuracy: 0.8992\n",
      "Epoch 74: val_loss improved from 0.37939 to 0.37120, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8966 - val_loss: 0.3712 - val_accuracy: 0.8865\n",
      "Epoch 75/100\n",
      "160/186 [========================>.....] - ETA: 0s - loss: 0.2976 - accuracy: 0.8969\n",
      "Epoch 75: val_loss did not improve from 0.37120\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8942 - val_loss: 0.3969 - val_accuracy: 0.8826\n",
      "Epoch 76/100\n",
      "165/186 [=========================>....] - ETA: 0s - loss: 0.3372 - accuracy: 0.8898\n",
      "Epoch 76: val_loss did not improve from 0.37120\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8903 - val_loss: 0.3970 - val_accuracy: 0.8855\n",
      "Epoch 77/100\n",
      "166/186 [=========================>....] - ETA: 0s - loss: 0.3102 - accuracy: 0.8948\n",
      "Epoch 77: val_loss did not improve from 0.37120\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8939 - val_loss: 0.3784 - val_accuracy: 0.8807\n",
      "Epoch 78/100\n",
      "168/186 [==========================>...] - ETA: 0s - loss: 0.3343 - accuracy: 0.8884\n",
      "Epoch 78: val_loss improved from 0.37120 to 0.36512, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8888 - val_loss: 0.3651 - val_accuracy: 0.8931\n",
      "Epoch 79/100\n",
      "163/186 [=========================>....] - ETA: 0s - loss: 0.3033 - accuracy: 0.9016\n",
      "Epoch 79: val_loss did not improve from 0.36512\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3057 - accuracy: 0.9011 - val_loss: 0.3714 - val_accuracy: 0.8950\n",
      "Epoch 80/100\n",
      "184/186 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.8981\n",
      "Epoch 80: val_loss improved from 0.36512 to 0.36477, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3163 - accuracy: 0.8979 - val_loss: 0.3648 - val_accuracy: 0.8922\n",
      "Epoch 81/100\n",
      "167/186 [=========================>....] - ETA: 0s - loss: 0.3191 - accuracy: 0.8932\n",
      "Epoch 81: val_loss improved from 0.36477 to 0.36248, saving model to saved_models\\audio_classification.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8927 - val_loss: 0.3625 - val_accuracy: 0.8912\n",
      "Epoch 82/100\n",
      "183/186 [============================>.] - ETA: 0s - loss: 0.3035 - accuracy: 0.8958\n",
      "Epoch 82: val_loss did not improve from 0.36248\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8954 - val_loss: 0.3821 - val_accuracy: 0.8941\n",
      "Epoch 83/100\n",
      "185/186 [============================>.] - ETA: 0s - loss: 0.3071 - accuracy: 0.8988\n",
      "Epoch 83: val_loss did not improve from 0.36248\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8984 - val_loss: 0.3690 - val_accuracy: 0.8931\n",
      "Epoch 84/100\n",
      "174/186 [===========================>..] - ETA: 0s - loss: 0.3045 - accuracy: 0.8955\n",
      "Epoch 84: val_loss improved from 0.36248 to 0.35959, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8942 - val_loss: 0.3596 - val_accuracy: 0.8884\n",
      "Epoch 85/100\n",
      "181/186 [============================>.] - ETA: 0s - loss: 0.3026 - accuracy: 0.8954\n",
      "Epoch 85: val_loss did not improve from 0.35959\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3030 - accuracy: 0.8947 - val_loss: 0.3849 - val_accuracy: 0.8912\n",
      "Epoch 86/100\n",
      "179/186 [===========================>..] - ETA: 0s - loss: 0.3044 - accuracy: 0.8996\n",
      "Epoch 86: val_loss did not improve from 0.35959\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8996 - val_loss: 0.3748 - val_accuracy: 0.8912\n",
      "Epoch 87/100\n",
      "184/186 [============================>.] - ETA: 0s - loss: 0.2745 - accuracy: 0.9110\n",
      "Epoch 87: val_loss did not improve from 0.35959\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.9112 - val_loss: 0.3741 - val_accuracy: 0.8884\n",
      "Epoch 88/100\n",
      "181/186 [============================>.] - ETA: 0s - loss: 0.3144 - accuracy: 0.8930\n",
      "Epoch 88: val_loss did not improve from 0.35959\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8927 - val_loss: 0.4059 - val_accuracy: 0.8865\n",
      "Epoch 89/100\n",
      "179/186 [===========================>..] - ETA: 0s - loss: 0.2916 - accuracy: 0.9005\n",
      "Epoch 89: val_loss did not improve from 0.35959\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8996 - val_loss: 0.3616 - val_accuracy: 0.8893\n",
      "Epoch 90/100\n",
      "184/186 [============================>.] - ETA: 0s - loss: 0.3057 - accuracy: 0.8959\n",
      "Epoch 90: val_loss did not improve from 0.35959\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8959 - val_loss: 0.3622 - val_accuracy: 0.8817\n",
      "Epoch 91/100\n",
      "174/186 [===========================>..] - ETA: 0s - loss: 0.2926 - accuracy: 0.9010\n",
      "Epoch 91: val_loss did not improve from 0.35959\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.9021 - val_loss: 0.3919 - val_accuracy: 0.8826\n",
      "Epoch 92/100\n",
      "180/186 [============================>.] - ETA: 0s - loss: 0.3009 - accuracy: 0.8983\n",
      "Epoch 92: val_loss improved from 0.35959 to 0.34142, saving model to saved_models\\audio_classification.hdf5\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8989 - val_loss: 0.3414 - val_accuracy: 0.8865\n",
      "Epoch 93/100\n",
      "175/186 [===========================>..] - ETA: 0s - loss: 0.2922 - accuracy: 0.9005\n",
      "Epoch 93: val_loss did not improve from 0.34142\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.9016 - val_loss: 0.3749 - val_accuracy: 0.8874\n",
      "Epoch 94/100\n",
      "182/186 [============================>.] - ETA: 0s - loss: 0.2791 - accuracy: 0.9052\n",
      "Epoch 94: val_loss did not improve from 0.34142\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2784 - accuracy: 0.9053 - val_loss: 0.3538 - val_accuracy: 0.8979\n",
      "Epoch 95/100\n",
      "178/186 [===========================>..] - ETA: 0s - loss: 0.2871 - accuracy: 0.9041\n",
      "Epoch 95: val_loss did not improve from 0.34142\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.9033 - val_loss: 0.3794 - val_accuracy: 0.8865\n",
      "Epoch 96/100\n",
      "181/186 [============================>.] - ETA: 0s - loss: 0.2898 - accuracy: 0.9023\n",
      "Epoch 96: val_loss did not improve from 0.34142\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.9021 - val_loss: 0.3814 - val_accuracy: 0.8836\n",
      "Epoch 97/100\n",
      "170/186 [==========================>...] - ETA: 0s - loss: 0.2803 - accuracy: 0.9050\n",
      "Epoch 97: val_loss did not improve from 0.34142\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.9070 - val_loss: 0.3647 - val_accuracy: 0.8922\n",
      "Epoch 98/100\n",
      "169/186 [==========================>...] - ETA: 0s - loss: 0.2604 - accuracy: 0.9112\n",
      "Epoch 98: val_loss did not improve from 0.34142\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.9107 - val_loss: 0.3415 - val_accuracy: 0.9027\n",
      "Epoch 99/100\n",
      "176/186 [===========================>..] - ETA: 0s - loss: 0.2929 - accuracy: 0.9025\n",
      "Epoch 99: val_loss did not improve from 0.34142\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.9038 - val_loss: 0.3481 - val_accuracy: 0.9017\n",
      "Epoch 100/100\n",
      "172/186 [==========================>...] - ETA: 0s - loss: 0.2943 - accuracy: 0.9023\n",
      "Epoch 100: val_loss did not improve from 0.34142\n",
      "186/186 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.9026 - val_loss: 0.3562 - val_accuracy: 0.8960\n",
      "Training completed in time:  0:00:38.549011\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_valid, y_valid), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abf1e4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 778us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9f6e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9738925099372864\n",
      "Testing Accuracy:  0.8935317397117615\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
